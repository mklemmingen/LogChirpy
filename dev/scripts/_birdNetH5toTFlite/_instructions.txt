====================================================================================
                          BIRDNET V2.4 MODEL CONVERSION STATUS
====================================================================================

CURRENT STATE (UPDATED): Model conversion attempted but faced TensorFlow compatibility issues.
Current setup now works with existing model in compatibility mode.

CONVERSION ATTEMPT RESULTS:
✅ Python environment set up (NumPy 2.2.5, TensorFlow 2.19.0)
✅ Official H5 models located (audio-model.h5, meta-model.h5)
❌ Conversion failed due to TensorFlow version incompatibilities:
   - Custom layers (MelSpecLayerSimple, MDataLayer) cause loading issues
   - Model saved with older TF version has deprecated parameters
   - "groups" parameter in DepthwiseConv2D not supported in current TF version

CURRENT MODEL ANALYSIS:
- Input: [1, 224, 224, 3] (image-like format)
- Output: [1, 400] (400 classes)
- Type: NOT the official BirdNet v2.4 model
- Status: Works but limited to 400 species

WORKAROUND IMPLEMENTED:
✅ Audio preprocessing updated to generate [224, 224, 3] format
✅ Model validation enhanced to handle size mismatches gracefully
✅ Classification works with available 400 classes (limited but functional)
✅ Error handling prevents crashes when model/label mismatch occurs

OFFICIAL SOURCES:
- Zenodo: https://zenodo.org/records/15050749
- GitHub: https://github.com/birdnet-team/BirdNET-Analyzer
- Documentation: https://birdnet-team.github.io/BirdNET-Analyzer/

FUTURE IMPROVEMENTS:
1. Use compatible TensorFlow version (2.8-2.12) for H5 conversion
2. Create custom layer definitions for current TF version
3. Alternative: Download pre-converted official BirdNet TFLite model if available
4. Update to full 6522-class model once conversion succeeds

CURRENT FUNCTIONALITY:
✅ App works without crashes
✅ Audio classification functional (limited to 400 species)
✅ Proper error handling for model mismatches
✅ Compatible audio preprocessing pipeline

====================================================================================


BirdNET-Analyzer Documentation

Welcome to the BirdNET-Analyzer documentation! This guide provides detailed information on installing, configuring, and using BirdNET-Analyzer.

Contents:

    Download & Setup
    Usage
    Models
    Best practices
    Implementation details
    FAQ
    Showroom
    BirdNET in R
    BirdNET-Tiny
    How To Contibute

Introduction

BirdNET-Analyzer is an open source tool for analyzing bird calls using machine learning models. It can process large amounts of audio recordings and identify (bird) species based on their calls.

Get started by listening to this AI-generated introduction of the BirdNET-Analyzer:
Your browser does not support the audio element.

Source: Google NotebookLM
Citing BirdNET-Analyzer

Feel free to use BirdNET for your acoustic analyses and research. If you do, please cite as:

@article{kahl2021birdnet,
  title={BirdNET: A deep learning solution for avian diversity monitoring},
  author={Kahl, Stefan and Wood, Connor M and Eibl, Maximilian and Klinck, Holger},
  journal={Ecological Informatics},
  volume={61},
  pages={101236},
  year={2021},
  publisher={Elsevier}
}

About

Developed by the K. Lisa Yang Center for Conservation Bioacoustics at the Cornell Lab of Ornithology in collaboration with Chemnitz University of Technology.

Go to https://birdnet.cornell.edu to learn more about the project.

Want to use BirdNET to analyze a large dataset? Don’t hesitate to contact us: ccb-birdnet@cornell.edu

We also have a discussion forum on Reddit if you have a general question or just want to chat.

Have a question, remark, or feature request? Please start a new issue thread to let us know. Feel free to submit a pull request.
More tools and resources

We also provide Python and R packages to interact with BirdNET models, as well as training and deployment tools for microcontrollers. Make sure to check out our other repositories at https://github.com/birdnet-team.
Projects map

We have created an interactive map of projects that use BirdNET. If you are working on a project that uses BirdNET, please let us know and we can add your project to the map.

You can access the map here: Open projects map

Please refer to the projects map documentation for more information on how to contribute.
License

Source Code: The source code for this project is licensed under the MIT License

Models: The models used in this project are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)

Please ensure you review and adhere to the specific license terms provided with each model.

Please note that all educational and research purposes are considered non-commercial use and it is therefore freely permitted to use BirdNET models in any way.
Funding

This project is supported by Jake Holshuh (Cornell class of ´69) and The Arthur Vining Davis Foundations. Our work in the K. Lisa Yang Center for Conservation Bioacoustics is made possible by the generosity of K. Lisa Yang to advance innovative conservation technologies to inspire and inform the conservation of wildlife and habitats.

The development of BirdNET is supported by the German Federal Ministry of Education and Research through the project “BirdNET+” (FKZ 01|S22072). The German Federal Ministry for the Environment, Nature Conservation and Nuclear Safety contributes through the “DeepBirdDetect” project (FKZ 67KI31040E). In addition, the Deutsche Bundesstiftung Umwelt supports BirdNET through the project “RangerSound” (project 39263/01).


Models
V2.4, June 2023

    more than 6,000 species worldwide

    covers frequencies from 0 Hz to 15 kHz with two-channel spectrogram (one for low and one for high frequencies)

    0.826 GFLOPs, 50.5 MB as FP32

    enhanced and optimized metadata model

    global selection of species (birds and non-birds) with 6,522 classes (incl. 11 non-event classes)

Technical Details

    48 kHz sampling rate (we up- and downsample automatically and can deal with artifacts from lower sampling rates)

    we compute 2 mel spectrograms as input for the convolutional neural network:

            first one has fmin = 0 Hz and fmax = 3000; nfft = 2048; hop size = 278; 96 mel bins

            second one has fmin = 500 Hz and fmax = 15 kHz; nfft = 1024; hop size = 280; 96 mel bins

    both spectrograms have a final resolution of 96x511 pixels

    raw audio will be normalized between -1 and 1 before spectrogram conversion

    we use non-linear magnitude scaling as mentioned in Schlüter 2018

    V2.4 uses an EfficienNetB0-like backbone with a final embedding size of 1024

    See this comment for more details

Species range model V2.4 - V2, Jan 2024

    updated species range model based on eBird data

    more accurate (spatial) species range prediction

    slightly increased long-tail distribution in the temporal resolution

    see this discussion post for more details

Using older models

Older models can also be used as custom classifiers in the GUI or using the –classifier argument in the birdnet_analyzer.analyze command line interface.

Just download your desired model version and unzip.

    GUI: Select the *_Model_FP32.tflite file under Species selection / Custom classifier

    CLI: python -m birdnet_analyzer ... --classifier 'path_to_Model_FP32.tflite'

Model Version History

Note

All models listed here are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0).
V2.4

    more than 6,000 species worldwide

    covers frequencies from 0 Hz to 15 kHz with two-channel spectrogram (one for low and one for high frequencies)

    0.826 GFLOPs, 50.5 MB as FP32

    enhanced and optimized metadata model

    global selection of species (birds and non-birds) with 6,522 classes (incl. 11 non-event classes)

    Download here: BirdNET-Analyzer-V2.4.zip

V2.3

    slightly larger (36.4 MB vs. 21.3 MB as FP32) but smaller computational footprint (0.698 vs. 1.31 GFLOPs) than V2.2

    larger embedding size (1024 vs 320) than V2.2 (hence the bigger model)

    enhanced and optimized metadata model

    global selection of species (birds and non-birds) with 3,337 classes (incl. 11 non-event classes)

    Download here: BirdNET-Analyzer-V2.3.zip

V2.2

    smaller (21.3 MB vs. 29.5 MB as FP32) and faster (1.31 vs 2.03 GFLOPs) than V2.1

    maintains same accuracy as V2.1 despite more classes

    global selection of species (birds and non-birds) with 3,337 classes (incl. 11 non-event classes)

    Download here: BirdNET-Analyzer-V2.2.zip

V2.1

    same model architecture as V2.0

    extended 2022 training data

    global selection of species (birds and non-birds) with 2,434 classes (incl. 11 non-event classes)

    Download here: BirdNET-Analyzer-V2.1.zip

V2.0

    same model design as 1.4 but a bit wider

    extended 2022 training data

    global selection of species (birds and non-birds) with 1,328 classes (incl. 11 non-event classes)

    Download here: BirdNET-Analyzer-V2.0.zip

V1.4

    smaller, deeper, faster

    only 30% of the size of V1.3

    still linear spectrogram and EfficientNet blocks

    extended 2021 training data

    1,133 birds and non-birds for North America and Europe

    Download here: BirdNET-Analyzer-V1.4.zip

V1.3

    Model uses linear frequency scale for spectrograms

    uses V2 fusion blocks and V1 efficient blocks

    extended 2021 training data

    1,133 birds and non-birds for North America and Europe

    Download here: BirdNET-Analyzer-V1.3.zip

V1.2

    Model based on EfficientNet V2 blocks

    uses V2 fusion blocks and V1 efficient blocks

    extended 2021 training data

    1,133 birds and non-birds for North America and Europe

    Download here: BirdNET-Analyzer-V1.2.zip

V1.1

    Model based on Wide-ResNet (aka “App model”)

    extended 2021 training data

    1,133 birds and non-birds for North America and Europe

    Download here: BirdNET-Analyzer-V1.1.zip

App Model

    Model based on Wide-ResNet

    ~3,000 species worldwide

    currently deployed as BirdNET app model

    Download here: BirdNET-Analyzer-App-Model.zip

Crop Modes

This page describes the different crop modes available for the training and embeddings-search feature the BirdNET-Analyzer. In general a crop mode selection will be available in cases where audio files longer than 3 seconds are processed. With the the crop mode you can specify how the audio files should be cropped into 3 second snippets.
1. Center

This crop mode will take the center 3 seconds of the audio file.
2. First

This crop mode will take the first 3 seconds of the audio file.
3. Segments

With this crop mode you can also specify an overlap. The crop mode will then split the audio file into 3 second segments with the specified overlap. In the training feature this will result in multiple training examples that are generated from the same audio file. In the search feature the similarity measure will be averaged over all segments of the query example.
4. Smart

# TODO

